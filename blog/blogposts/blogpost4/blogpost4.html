<html>
	<head>
		<title> بلاگ </title>
		<link type="text/css"  href="blogpost4css.css" rel="stylesheet"/>
		<link type="text/css" href="../../../font.css" rel="stylesheet"/>
		<script type="text/javascript" src="criticismjs.js"></script>
		<meta charset="utf-8"/>
		<link rel="shortcut icon" href="../../../images/shortcuticon.png"/>
		<meta name="viewport" content="width=device-width, initial-scale=1.0" />


	</head>
	
	
	<body>
	
	<div class="hedder">
		<div class="heddermenu">
			<div class="heddermenuin">
			<ul class="ulright">
				
				
				
				<li class="li11">
				<a href="../../../index.html"class="a1">
					صفحه اصلی
					</a>
				</li>				
					
				
				
				<li class="li1">
					<a href="../../../aboutme/aboutme.html" class="a1">
					درباره من
					</a >
				</li>				
				
				
				
				<li class="li1">
				<a href="../../../contactme/contactme.html" class="a1">
					تماس با من
					</a>
				</li>				
				
				
				
				<li class="li1">
				<a href="#" class="a1">
					دست نوشته ها
					</a>
				</li>
				
				
				
				<li class="li1">
				<a href="../../../blog/blog.html" class="a11">
					بلاگ
					</a>
				</li>		
			</ul>
			<div class="logoarea">
				<img src="../../../images/logo.png" class="logoimg"/>
			</div>
			<ul class="ulleft">
				
				<li class="li21">
				<a href="../../../criticism/criticism.html" class="a1">
					از من انتقاد کن
			</a>
				</li>			
				
				
				
				<li class="li2">
				<a href="../../../book/book.html" class="a2">
					کتاب معرفی کن
					</a>
				</li>				
				
				
				
				<li class="li2">
				<a href="https://idpay.ir/moamr" target="_blank" class="a2">
				پرداخت آنلاین
				</a>
					</li>
				
				
				
				
				<li class="li2">
				<a href="../../../works/works.html" class="a2">
					نمونه کارها
					</a>
				</li>				
				
			</ul>
			</div>
		</div>	
	<p class="addrestxt"><a class="a2" href="../../../index.html">  صفحه نخست </a>● <a class="a2" href="../../blog.html">بلاگ</a> ● <a class="a2" href="blogpost4.html">فروپاشی حریم خصوصی؛ آیا باید به نظارت دولت جهانی و فرابشری تن داد؟</a> </p>
	<div class="d2">
		<p class="criticismtxttitr">
فروپاشی حریم خصوصی؛ آیا باید به نظارت دولت جهانی و فرابشری تن داد؟
	</p>

	<img class="criticismimg"src="../../../images/blogimg4.jpg"/>

	<p class="criticismtxt">

نیک باستروم در سخنرانی اخیرش در TED 2019، در ایده‌‌ای جنجالی اعلام کرد بشر برای جلوگیری از نابودی خود به‌دست فناوری، مجبور است به نظارت دولت فراگیر هوش مصنوعی تن دهد.<br>
<br>
<br>
شاید نام نیک باستروم برایتان آشنا باشد. وی فیلسوفی معاصر است که بیش‌از‌همه به‌‌‌دلیل پیش‌‌بینی‌‌های ترسناکش درباره‌ی آینده‌‌ی بشر شهرتی جهانی یافته و هم‌‌اکنون، برخی دیدگاه‌هایش توانسته حمایت بزرگانی از دنیای فناوری، نظیر ایلان ماسک را نیز جلب کند. چندی پیش مطلبی را در زومیت منتشر کردیم که به دفاعیات یکی از دانشمندان ام‌‌آی‌‌تی از «فرضیه‌‌ی شبیه‌‌سازی» پرداخته بود؛ فرضیه‌‌ای که ریشه‌‌ی آن به یکی دیگر از ایده‌‌های باستروم در ۱۵ سال پیش بازمی‌‌گردد که با اظهارات اخیر ماسک، باردیگر در محافل علمی جهان بر سر زبان‌ها افتاد.

<br>
گویا سناریوهای تاریک باستروم برای جهان تمامی ندارد. این‌‌بار نویسنده‌‌ی کتاب «برهان شبیه‌سازی» می‌گوید تکنولوژی مخرب می‌تواند بشر را نابود کند و تنها راه جلوگیری از آن، استقرار دولت جهانی مبتنی‌‌بر هوش مصنوعی است. جملاتی که شاید بسیاری را به یاد دنیای تاریکی می‌اندازد که ۷۰ سال پیش، جورج اورل در رمان معروف ۱۹۸۴ از آن سخن می‌گفت.

<br>
		<span style="font-size:25pt;">ناظر کبیر (برادر بزرگ)</span>
<br>
باستروم، فیلسوف شهیر دانشگاه آکسفورد، ۱۵ سال پس از ارائه‌ی دیدگاه‌های جنجال‌برانگیزش درباره‌ی ماهیت واقعی بشر، نظریه‌‌ی دورازذهن دیگری در چنته دارد و این‌بار هم گویا جایی برای خوش‌‌بینی به آینده‌‌ی بشر نمی‌‌بیند.
<br>
چهارشنبه‌‌ی گذشته، نیک باستروم در کنفرانس TED 2019 در ونکوور کانادا، روی سکو رفت تا برخی از نکات مربوط‌به آخرین مقاله‌‌ی خود را به‌نام «فرضیه‌‌ی جهان آسیب‌پذیر» با جهانیان به‌اشتراک بگذارد.
	<br>
	<span style="font-size:25pt;color:red">بشر برای جلوگیری از نابودی خود به‌وسیله‌ی فناوری، نیازمند نظارت دولتی فراگیر است</span>
			<br>
			</p>
	<img class="criticismimg"src="../../../images/blogimg42.jpg"/>
		<p class="criticismtxt">
		<span style="font-size:25pt;">توپ‌های سیاه</span>
		<br>
باستروم استدلال خود را با مثالی از گلدانی بزرگ پُر از توپ توضیح می‌‌دهد که پیش روی بشر قرار دارد. هرکدام از این توپ‌‌ها با رنگ‌‌های مختص‌‌ به خود، نمایانگر ایده‌‌ای متفاوت یا فناوری جدیدی هستند: سفید (به‌‌معنای مفید) و خاکستری (به‌‌معنای نسبتا مضر، اما نه ویرانگر) و سیاه (به‌‌معنای ویرانگر و نابودکننده‌‌ی تمدن بشر).

<br>
باتوجه‌به مدل تعریف‌‌شده‌ی باستروم، بشر به‌‌طور مداوم توپی از درون این گلدان بیرون می‌کشد که دیگر به گلدان بازگرداندنی نیست و از بخت ما، هنوز کسی توپ سیاهی بیرون نکشیده است. در اینجا، وی تأکید ویژه‌‌ای بر کلمه‌‌ی «هنوز» دارد. باستروم در نوشته‌هایش می‌گوید:
<br>		
<br>
اگر تحقیقات علمی و تکنولوژیکی همین‌‌طور ادامه یابد، درنهایت، به آن (توپ سیاه) خواهیم رسید و آن را بیرون خواهیم کشید.
<br>
<br>
بنابر گفته‌‌ی باستروم، تنها دلیلی که هنوز توپ سیاهی بیرون نکشیده‌‌ایم، بخت بلند ما بوده است. از دیدگاه وی، حتی پدیده‌‌ای مانند «گرمایش جهانی» نیز می‌‌توانست بسیار بدتر از آن‌‌ چیزی باشد که امروز، شاهدش هستیم.
<br>
<span style="font-size:25pt;">خلع آزادی</span>
<br>
باستروم بر این باور است که توپ سیاهی که بنیان تمدن ما را نشانه خواهد رفت، نهایتا محصولی از فناوری خودِ ما خواهد بود؛ ازاین‌‌رو، باید با اعمال نظارت روی خودمان، از ظهور چنین فناوری مخربی جلوگیری کنیم. او می‌افزاید برای جلوگیری از وقوع چنین اتفاقی، به دولت جهانی کاراتری نیاز داریم؛ دولتی که بتواند به‌‌سرعت هرگونه فناوری بالقوه‌‌‌ی ویرانگری را غیرقانونی اعلام کند.
<br>
درادامه، او می‌گوید به نظارت چنین دولت بزرگی باید تن دهیم و هر فرد باید نوعی تجهیز به‌‌شکل گردنبند را با عنوان «برچسب آزادی» به‌همراه داشته باشد تا این سیستم بتواند آنچه فرد می‌‌بیند و می‌‌شنود، با دوربین‌‌ها و میکروفن‌‌های نصب‌‌شده مخابره کند.
<br>
این برچسب‌ها به «ایستگاه‌های نظارت میهن‌پرستان» یا «مراکز آزادی» متصل می‌‌شوند تا در آنجا، هوش‌‌های مصنوعی تمامی داده‌‌ها را کنترل کنند و چنانچه کوچک‌ترین نشانه‌‌ای از توپ سیاه تشخیص داده شود، افرادی با عنوان «افسران آزادی» برای رسیدگی به آن گماشته خواهند شد.

</p>		
	<img class="criticismimg"src="../../../images/blogimg43.jpg"/>
<p class="criticismtxt">

<span style="font-size:25pt;">شیاطین دوقلو</span>
<br>
پیش‌‌تر نیز مواردی از سوءاستفاده‌‌ی افراد را از سامانه‌‌های نظارت جمعی شاهد بوده‌‌ایم؛ اما آن سیستم‌‌ها بسیار ناقص‌‌تر از آن‌‌ چیزی به‌نظر می‌‌رسند که در نظریه‌‌ی باستروم پیشنهاد شده است. چنین اظهاراتی به‌‌‌ویژه در کنفرانسی مانند TED بسیار بحث‌برانگیز جلوه می‌کند که امسال روی استراتژی‌‌های تضمین حریم خصوصی در عصر دیجیتال تمرکز داشته است. البته، خود وی نیز بر این موضوع صحه گذاشته که ممکن است چنین سناریویی اصلا روی ندهد.

<br>	
بااین‌حال، از دیدگاه باستروم، چنانچه قرار باشد میان تن‌‌دادن به کنترل تمامی رفتارهای خود و نابودی کل تمدن یکی را انتخاب کنیم، شاید بهتر است گزینه‌‌ی اول را انتخاب کنیم. او در خلال کنفرانس TED رو به حضار گفت:
<br>	
		<br>
واضح است جنبه‌های منفی بی‌‌شمار و خطرهای فراوانی در تن‌‌دادن به سیستم نظارت جمعی یا دولت جهانی وجود دارد. من فقط قصد دارم به این اشاره کنم که چنانچه بخت با ما یار باشد، این تنها راه پیش روی دنیا است که بتواند از (عواقب) انتخاب توپ سیاه جان سالم به‌‌در ببرد.
<br>


<span style="color:orange;">روزبه خانجانی-زومیت-</a>
</p>
	
	</div>

						<div class="bottommenu">
				<p class="bottommenutxt">
			 © 2019 کلیه حقوق سایت محفوظ است
			</p>
			</div>
	</body>
	</html>